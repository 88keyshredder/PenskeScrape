name: Selenium Scraper Test

# Control when the workflow will run
on:
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      location:
        description: 'Pickup Location (City, State)'
        required: true
        default: 'Tempe, AZ'
      pickup_date:
        description: 'Pickup Date (MM/DD/YYYY)'
        required: true
        default: '04/30/2025'
      dropoff_date:
        description: 'Dropoff Date (MM/DD/YYYY)'
        required: true
        default: '04/30/2025'

# A workflow run is made up of one or more jobs
jobs:
  # Job to run the Selenium scraper
  scrape:
    runs-on: ubuntu-latest

    steps:
      # Checkout the repository content
      - name: Checkout
        uses: actions/checkout@v3

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      # Install Chrome with ChromeDriver
      - name: Setup Chrome with ChromeDriver
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable
          install-chromedriver: true
        
      # Check Chrome and ChromeDriver versions
      - name: Check versions
        run: |
          chrome --version
          chromedriver --version
          
      # Install dependencies directly with compatible versions
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install compatible versions of numpy and pandas
          pip install numpy==1.23.5
          pip install pandas==1.5.3
          pip install selenium==4.9.1 requests==2.31.0
          # Modified to use local ChromeDriver instead of webdriver-manager
          # No need for webdriver-manager anymore
          
          # Verify installations
          python -c "import numpy; print(f'NumPy version: {numpy.__version__}')"
          python -c "import pandas; print(f'Pandas version: {pandas.__version__}')"
          python -c "import selenium; print(f'Selenium version: {selenium.__version__}')"

      # Run environment test
      - name: Test environment setup
        run: python test_environment.py
        
      # Run the scraper with modified code to use the local ChromeDriver
      - name: Run Selenium scraper
        run: |
          # Modify the scraper.py file to use the local ChromeDriver
          sed -i 's/service = Service(ChromeDriverManager().install())/service = Service("chromedriver")/' scraper.py
          # Run the scraper
          python scraper.py "${{ github.event.inputs.location }}" "${{ github.event.inputs.pickup_date }}" "${{ github.event.inputs.dropoff_date }}" "penske_data.csv"

      # Upload results as GitHub artifacts
      - name: Upload CSV Result
        uses: actions/upload-artifact@v4
        with:
          name: penske-data-csv
          path: penske_data.csv
          
      - name: Upload JSON Result
        uses: actions/upload-artifact@v4
        with:
          name: penske-data-json
          path: penske_data.json
